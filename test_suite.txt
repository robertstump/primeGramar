Returns non-NULL base and start
Allocates expected total size (usable + guards)
Base is page-aligned
Guard pages are correctly marked with PROT_NONE (use mprotect test or SIGSEGV trap if brave)
Clean unmap with releasePages() leaves pointers null

2. createPageArena()
Arena’s base points to next free offset
arena.size == requested size (rounded if applicable)
arena.offset == 0, arena.previous == 0
map->offset is advanced correctly after each creation
Multiple arenas do not overlap

🧮 3. arenaPageAlloc()
Returns non-NULL pointer on valid allocation
Pointer is aligned to requested alignment
Multiple consecutive allocations do not overlap
Allocation increases offset as expected
arena->offset never exceeds arena->size

↩️ 4. Push/Pop
arenaPagePush() followed by alloc then arenaPagePop() restores original offset
memMapPush()/memMapPop() same logic for multiple PageArena allocations

🧹 5. destroyPageArena()
Zeros arena->base, size, and offset
Arena is inert after destruction (i.e., alloc from it fails)
⚠️ Edge Cases You Might Miss

These are situations that pass casual testing but break real-world use:

🧨 1. Zero-size allocations
Allocating arenaPageAlloc(arena, 0, ALIGN_16)—should return aligned pointer or NULL?
Ensure arena->offset doesn’t shift on zero

🔫 2. Alignment larger than arena size
arenaPageAlloc(&arena, 64, ALIGN_128); // alignment > arena->size
→ Must fail gracefully.

🧩 3. Allocations that exactly fill arena
arena.size = 1024;
arenaPageAlloc(&arena, 1024, ALIGN_1);  // full fill
arenaPageAlloc(&arena, 1, ALIGN_1);     // should fail

🧬 4. Multiple arenas from same memMap
Confirm non-overlapping arenas
Confirm alignment still holds between them
Confirm destruction of one arena doesn’t impact others

🚨 5. Accessing memory outside mapped region
→ Optional: install a SIGSEGV handler and try writing into guard page to confirm it trips (advanced, but satisfying)

🔁 6. Repeated use
resetPageArena() followed by reallocation
Should re-use space exactly, not leak or shift offsets

🧼 7. Release
releasePages() followed by access → segfault (you could test indirectly by ensuring next access is protected)
🧪 Bonus Ideas (Optional)

Benchmark arena vs malloc for large batch allocations
Simulate fragmentation: lots of small allocations, then push/pop, then big allocation

